{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Deep Reinforcement Learning  in Action Ch2 V2 of the code\n",
    "## from multi-armed Bandits to contextual bandits\n",
    "### Chapter 2\n",
    "#modified with comments jw april 25,2019 - azure ml meetup\n",
    "#contextual bandit is a variation of multi-armed bandit. the contextual refers to the current state\n",
    "#of the simulation which is used as input to the deep neural net model to predict the reward. \n",
    "#that predicted reward is then comapared against the calculated reward, representing the loss function,\n",
    "#which is what our DNN tries to minimize.\n",
    "#try to use more intuitive naming\n",
    "#site refers to one of 10 possible web sites to be visiting\n",
    "#ads refers to one of 10 ads to show given a site that is currently being visited\n",
    "#there is a random probability of someone clicking on an ad they see on that site\n",
    "#the agent tries to find a strategy that optimizes rewards where rewards are based on the probability of clikcing on a ad\n",
    "#this is a simulation of the above with some simple assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the main contextual bandit class we'll be using as our environment/simulator to train a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ads here represent the choices (ads) to select from \n",
    "#sites represent the current part of the web site visited - renaming that to site\n",
    "#goal is to have a matrix of row(site) by column(ad)\n",
    "#step 1 - rename state to site - ok 4/22\n",
    "#step 2 - rename ads to ads since that is the choice to be made (select the ad to show given at site 'x')\n",
    "# and rename  to ad \n",
    "np.set_printoptions(precision=3) \n",
    "\n",
    "class ContextBandit:\n",
    "    def __init__(self, ads=10):\n",
    "        self.ads   = ads\n",
    "        self.sites = ads                  #convenience - no need to have a 10 by 10 matrix\n",
    "        self.init_distribution(ads)\n",
    "        self.update_site()                #selects a site at random\n",
    "        print('initial ads probs for a site ',self.site,' are  ', self.bandit_matrix[self.site])\n",
    "        #print('initial site value is   ',self.site)\n",
    "        #print('initial matrix is       ',self.bandit_matrix)\n",
    "        \n",
    "    def init_distribution(self, ads):\n",
    "        # Num sites = Num ads to keep things simple\n",
    "        self.bandit_matrix = np.random.rand(ads,ads)\n",
    "        #each row represents a site, each column an ad\n",
    "        \n",
    "        #rewards are calculated based on probability with the probability coming from\n",
    "        #the /site matrix location set up in the class initializer\n",
    "        #note how reward is not static but probabilistic which is quite different than our multi-armed bandit model\n",
    "    def reward(self, prob):\n",
    "        reward = 0\n",
    "        for i in range(self.ads):\n",
    "            if random.random() < prob:\n",
    "                reward += 1\n",
    "        #print('Reward returned is ', reward, ' for prob ', prob)        \n",
    "        return reward\n",
    "        \n",
    "    def get_site(self):\n",
    "        return self.site\n",
    "    \n",
    "    def update_site(self):\n",
    "        self.site = np.random.randint(0,self.sites)\n",
    "        \n",
    "    def get_reward(self,ad):\n",
    "        return self.reward(self.bandit_matrix[self.get_site()][ad])\n",
    "        \n",
    "    def choose_ad(self,ad ):\n",
    "        reward = self.get_reward(ad)\n",
    "        self.update_site()\n",
    "        return reward\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our simple neural network model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#run a single simulation event               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type is  <bound method Module.type of Sequential(\n",
      "  (0): Linear(in_features=10, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (3): ReLU()\n",
      ")>\n",
      "initial ads probs for a site  6  are   [0.502 0.905 0.963 0.655 0.045 0.208 0.428 0.598 0.858 0.025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "def softmax(av, tau=1.12):\n",
    "    n     = len(av)\n",
    "    probs = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        softm    = ( np.exp(av[i] / tau) / np.sum( np.exp(av[:] / tau) ) )\n",
    "        probs[i] = softm\n",
    "    return probs\n",
    "\n",
    "def one_hot(N, pos, val=1):\n",
    "    one_hot_vec      = np.zeros(N)\n",
    "    one_hot_vec[pos] = val\n",
    "    return one_hot_vec\n",
    "\n",
    "ads   = 10 #also sets our site space to 10 - resulting in a 10 by 10 matrix of ads/sites\n",
    "sites = 10\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 1, sites, 100, ads\n",
    "\n",
    "model = th.nn.Sequential(\n",
    "    th.nn.Linear(D_in, H),\n",
    "    th.nn.ReLU(),\n",
    "    th.nn.Linear(H, D_out),\n",
    "    th.nn.ReLU(),\n",
    ")\n",
    "print(\"model type is \",model.type)\n",
    "\n",
    "loss_fn = th.nn.MSELoss(size_average=False)\n",
    "env=None\n",
    "env = ContextBandit(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---smoke test of ContextBandit---\n",
      "initial ads probs for a site  4  are   [0.368 0.997 0.058 0.543 0.576 0.573 0.351 0.783 0.339 0.794]\n",
      "tsoftsum is  tensor(1., grad_fn=<SumBackward0>)\n",
      "tsoft  tensor([0.0977, 0.0977, 0.0984, 0.1059, 0.0977, 0.0977, 0.1095, 0.0989, 0.0977,\n",
      "        0.0986], grad_fn=<SoftmaxBackward>)\n",
      "AVSOFTSUM 1.0000000154543365\n",
      "Normalized AVSOFTSUM  [0.099 0.099 0.099 0.103 0.099 0.099 0.105 0.099 0.099 0.099]\n",
      "ttsoft:  1.0\n",
      "tchoice  3\n",
      "test rewards  3\n",
      "onehotreward vector [0.    0.    0.007 0.081 0.    0.    0.113 0.012 0.    0.009]\n",
      "reward for choice  3  is  3\n",
      "updated reward tensor tensor([0.0000, 0.0000, 0.0067, 3.0000, 0.0000, 0.0000, 0.1133, 0.0123, 0.0000,\n",
      "        0.0089])\n",
      "Loss is  8.523297309875488\n"
     ]
    }
   ],
   "source": [
    "#smoke test cell \n",
    "print('---smoke test of ContextBandit---')\n",
    "np.set_printoptions(precision=3)\n",
    "envtest     = ContextBandit(10)\n",
    "testsite    = Variable(th.Tensor(one_hot(ads,env.get_site()))) \n",
    "\n",
    "tpredrew    = model(testsite)                        #produce reward predictions for current site\n",
    "tav_softmax = softmax(tpredrew.data.numpy(), tau=2.0) #turn reward distribution into probability distribution\n",
    "tsoft       = th.nn.functional.softmax(tpredrew,dim=0)\n",
    "print('tsoftsum is ',tsoft.sum())\n",
    "print('tsoft ',tsoft)\n",
    "print('AVSOFTSUM',tav_softmax.sum())\n",
    "tav_softmax /= tav_softmax.sum()\n",
    "print('Normalized AVSOFTSUM ',tav_softmax)             #make sure total prob adds to 1 - replace with tsoft\n",
    "ttsoft = tsoft.detach().numpy()                        #go from tensor to numpy which is what choice expects\n",
    "print('ttsoft: ',ttsoft.sum())\n",
    "#tchoice     = np.random.choice(ads, p=tav_softmax)    #randomly chhose an ad - notice p=av_softmax\n",
    "tchoice     = np.random.choice(ads,p=ttsoft)           #should work the same and removes unneeded steps\n",
    "print('tchoice ', tchoice)\n",
    "tcur_reward = env.choose_ad(tchoice)                   #smoke test of the ContextBandit\n",
    "print('test rewards ',tcur_reward)\n",
    "                                                         #value function calcs the ad chosen above \n",
    "tone_hot_reward          = tpredrew.data.numpy().copy()   #copy pred rewards to numpy array\n",
    "print('onehotreward vector',tone_hot_reward)\n",
    "tone_hot_reward[tchoice] = tcur_reward                    #set reward for choice just made\n",
    "print('reward for choice ',tchoice, ' is ', tcur_reward)\n",
    "treward = Variable(th.Tensor(tone_hot_reward))           #set reward to tensor form for the loss function\n",
    "print('updated reward tensor',treward)\n",
    "tloss   = loss_fn(tpredrew, treward) \n",
    "print('Loss is ',tloss.item())\n",
    "envtest = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the training function, which accepts an instantiated ContextBandit object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env):\n",
    "    epochs = 10000\n",
    "    #one-hot encode current site\n",
    "    cur_site = Variable(th.Tensor(one_hot(ads,env.get_site())))  #bootstrap before entering training loop\n",
    "    \n",
    "    reward_hist    = np.zeros(50)\n",
    "    reward_hist[:] = 5\n",
    "    runningMean    = np.average(reward_hist)\n",
    "    learning_rate  = 1e-2\n",
    "    optimizer      = th.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print('initial running mean: ',runningMean, ' learn rate: ',learning_rate, ' start site ', cur_site)\n",
    "    plt.xlabel(\"Tries\")\n",
    "    plt.ylabel(\"Mean Reward\")\n",
    "    for i in range(epochs):\n",
    "        predrew    = model(cur_site)                        #produce reward predictions for current site\n",
    "        av_softmax = softmax(predrew.data.numpy(), tau=2.0) #turn reward distribution into probability distribution\n",
    "        #print('AVSOFTSUM',av_softmax.sum())\n",
    "        av_softmax /= av_softmax.sum()                      #make sure total prob adds to 1\n",
    "        choice     = np.random.choice(ads, p=av_softmax)    #randomly chhose an ad - notice p=av_softmax\n",
    "        cur_reward = env.choose_ad(choice)                  #value function calcs the ad chosen above \n",
    "        one_hot_reward         = predrew.data.numpy().copy()   #copy pred rewards to numpy array\n",
    "        one_hot_reward[choice] = cur_reward                    #set reward for choice just made\n",
    "        reward = Variable(th.Tensor(one_hot_reward))           #set reward to tensor form for the loss function\n",
    "        loss   = loss_fn(predrew, reward)                      #calculate diff from prediction to observed reward\n",
    "        if i % 100 == 0: #initially 50\n",
    "            runningMean    = np.average(reward_hist)\n",
    "            reward_hist[:] = 0\n",
    "            plt.scatter(i, runningMean)\n",
    "            print('interim loss is ',loss.item(), ' at checkpoint ',i)\n",
    "            if (i == 2000):                                    #let's see if and how quickly the NN recovers\n",
    "                env.init_distribution(env.ads)\n",
    "            #print('onehotrewardchoice\\t',one_hot_reward[choice], ' reward ', reward) #4/25 test\n",
    "            #print('matrix row1 iteration mark: ',i, '\\n',env.bandit_matrix[0]) #jw added\n",
    "            #print('site in iteration number ',i, ' is \\n', env.get_site())\n",
    "            #print('running mean at iteration: ',i, ' is ', runningMean)\n",
    "        reward_hist[i % 50] = cur_reward\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "        #let's decompose the original function to its pieces\n",
    "        #cur_site = Variable(th.Tensor(one_hot(ads,env.get_site())))\n",
    "        asite    = env.get_site()           #fetch the site (a scalar number)\n",
    "        OH       = one_hot(ads,asite)       #takes number of ads and number of site ; return a one hot vector representation\n",
    "        cur_site = Variable(th.Tensor(OH))  #converts the onehot vector to a pytorch varaible tensor representation\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial running mean:  5.0  learn rate:  0.01  start site  tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "interim loss is  24.25139045715332  at checkpoint  0\n",
      "interim loss is  63.3709831237793  at checkpoint  100\n",
      "interim loss is  0.0007577802753075957  at checkpoint  200\n",
      "interim loss is  1.901370644569397  at checkpoint  300\n",
      "interim loss is  0.7175190448760986  at checkpoint  400\n",
      "interim loss is  1.418428659439087  at checkpoint  500\n",
      "interim loss is  0.43233922123908997  at checkpoint  600\n",
      "interim loss is  0.3753971755504608  at checkpoint  700\n",
      "interim loss is  1.9126267433166504  at checkpoint  800\n",
      "interim loss is  0.6969383955001831  at checkpoint  900\n",
      "interim loss is  0.10043423622846603  at checkpoint  1000\n",
      "interim loss is  9.517380714416504  at checkpoint  1100\n",
      "interim loss is  2.111253499984741  at checkpoint  1200\n",
      "interim loss is  0.7001474499702454  at checkpoint  1300\n",
      "interim loss is  10.073208808898926  at checkpoint  1400\n",
      "interim loss is  2.2772257328033447  at checkpoint  1500\n",
      "interim loss is  0.09042404592037201  at checkpoint  1600\n",
      "interim loss is  11.23754596710205  at checkpoint  1700\n",
      "interim loss is  1.427005648612976  at checkpoint  1800\n",
      "interim loss is  1.300282597541809  at checkpoint  1900\n",
      "interim loss is  0.08406347781419754  at checkpoint  2000\n",
      "interim loss is  2.161903142929077  at checkpoint  2100\n",
      "interim loss is  0.02315489389002323  at checkpoint  2200\n",
      "interim loss is  0.110272616147995  at checkpoint  2300\n",
      "interim loss is  6.123684406280518  at checkpoint  2400\n",
      "interim loss is  3.3912882804870605  at checkpoint  2500\n",
      "interim loss is  0.8825506567955017  at checkpoint  2600\n",
      "interim loss is  2.115823268890381  at checkpoint  2700\n",
      "interim loss is  0.026601377874612808  at checkpoint  2800\n",
      "interim loss is  0.11800610274076462  at checkpoint  2900\n",
      "interim loss is  0.0036880148109048605  at checkpoint  3000\n",
      "interim loss is  3.277275323867798  at checkpoint  3100\n",
      "interim loss is  6.503245094791055e-05  at checkpoint  3200\n",
      "interim loss is  0.9349876046180725  at checkpoint  3300\n",
      "interim loss is  0.0422900952398777  at checkpoint  3400\n",
      "interim loss is  0.705747663974762  at checkpoint  3500\n",
      "interim loss is  0.0030602787155658007  at checkpoint  3600\n",
      "interim loss is  5.888375759124756  at checkpoint  3700\n",
      "interim loss is  0.8760547041893005  at checkpoint  3800\n",
      "interim loss is  3.6904499530792236  at checkpoint  3900\n",
      "interim loss is  1.3622357845306396  at checkpoint  4000\n",
      "interim loss is  2.1946449279785156  at checkpoint  4100\n",
      "interim loss is  1.6796938180923462  at checkpoint  4200\n",
      "interim loss is  4.739378929138184  at checkpoint  4300\n",
      "interim loss is  0.0341310054063797  at checkpoint  4400\n",
      "interim loss is  1.161302924156189  at checkpoint  4500\n",
      "interim loss is  0.23311075568199158  at checkpoint  4600\n",
      "interim loss is  8.102705955505371  at checkpoint  4700\n",
      "interim loss is  0.3608913719654083  at checkpoint  4800\n",
      "interim loss is  0.1953466385602951  at checkpoint  4900\n",
      "interim loss is  0.052227672189474106  at checkpoint  5000\n",
      "interim loss is  0.08367736637592316  at checkpoint  5100\n",
      "interim loss is  0.004627740476280451  at checkpoint  5200\n",
      "interim loss is  0.34259894490242004  at checkpoint  5300\n",
      "interim loss is  2.139993190765381  at checkpoint  5400\n",
      "interim loss is  0.653145432472229  at checkpoint  5500\n",
      "interim loss is  2.388516664505005  at checkpoint  5600\n",
      "interim loss is  0.7797839641571045  at checkpoint  5700\n",
      "interim loss is  2.290769577026367  at checkpoint  5800\n",
      "interim loss is  0.17836898565292358  at checkpoint  5900\n",
      "interim loss is  1.8554271459579468  at checkpoint  6000\n",
      "interim loss is  0.49467581510543823  at checkpoint  6100\n",
      "interim loss is  0.3877323865890503  at checkpoint  6200\n",
      "interim loss is  2.0965325832366943  at checkpoint  6300\n",
      "interim loss is  0.2009492665529251  at checkpoint  6400\n",
      "interim loss is  15.40349292755127  at checkpoint  6500\n",
      "interim loss is  1.006847620010376  at checkpoint  6600\n",
      "interim loss is  0.935376763343811  at checkpoint  6700\n",
      "interim loss is  2.2695932388305664  at checkpoint  6800\n",
      "interim loss is  0.7070525884628296  at checkpoint  6900\n",
      "interim loss is  2.1668572425842285  at checkpoint  7000\n",
      "interim loss is  0.254686176776886  at checkpoint  7100\n",
      "interim loss is  0.14055420458316803  at checkpoint  7200\n",
      "interim loss is  0.46832579374313354  at checkpoint  7300\n",
      "interim loss is  12.922484397888184  at checkpoint  7400\n",
      "interim loss is  4.603482246398926  at checkpoint  7500\n",
      "interim loss is  0.3056618571281433  at checkpoint  7600\n",
      "interim loss is  0.1462104618549347  at checkpoint  7700\n",
      "interim loss is  0.00753831397742033  at checkpoint  7800\n",
      "interim loss is  0.09317591786384583  at checkpoint  7900\n",
      "interim loss is  0.5996078252792358  at checkpoint  8000\n",
      "interim loss is  0.8372528553009033  at checkpoint  8100\n",
      "interim loss is  1.3066575527191162  at checkpoint  8200\n",
      "interim loss is  0.1475723385810852  at checkpoint  8300\n",
      "interim loss is  0.26467064023017883  at checkpoint  8400\n",
      "interim loss is  0.0063257417641580105  at checkpoint  8500\n",
      "interim loss is  2.6811041831970215  at checkpoint  8600\n",
      "interim loss is  0.04200190305709839  at checkpoint  8700\n",
      "interim loss is  0.12921242415905  at checkpoint  8800\n",
      "interim loss is  5.74346399307251  at checkpoint  8900\n",
      "interim loss is  0.05746081471443176  at checkpoint  9000\n",
      "interim loss is  0.008591876365244389  at checkpoint  9100\n",
      "interim loss is  3.269155740737915  at checkpoint  9200\n",
      "interim loss is  0.06032345071434975  at checkpoint  9300\n",
      "interim loss is  8.751959800720215  at checkpoint  9400\n",
      "interim loss is  0.25621703267097473  at checkpoint  9500\n",
      "interim loss is  0.18852823972702026  at checkpoint  9600\n",
      "interim loss is  1.5196759700775146  at checkpoint  9700\n",
      "interim loss is  0.29730790853500366  at checkpoint  9800\n",
      "interim loss is  5.253481864929199  at checkpoint  9900\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
