{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a leaner version of CNTK tutorial 103D mostly to illustrate ways to examine tensors,shape,values and also using the Functional API over the Graph API for creating the convolutional network. There are minor differences but worth examining them in terms of error detection etc. There is a commented out debug section here that will only work on a terminal enabled environment. VS code is used for that but if you can run a jupyter notebook with its terminal activitated that should also work. If you run it w/o a terminal you may end up waiting for an input prompt that never arrives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - there are some local directory paths in here unique to my environment. Those will need to be changed back to their original default and generic settings as in the 103D tutorial - assuming you used 103A to download the data for training and testing. You will also want to alter the progprint output location and maybe the tensorboard output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNTK version 2.0\n",
      "CNTK sees device(s):  (CPU,)\n"
     ]
    }
   ],
   "source": [
    "#mninstF.py is the functional API version\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cntk as C\n",
    "import datetime\n",
    "\n",
    "print(\"CNTK version\",C.__version__)\n",
    "                                                    #let's set up safety and tracing flags\n",
    "C.debugging.set_computation_network_trace_level(1)  #1000 is more and 1000000 is intense\n",
    "C.logging.set_trace_level(2)                        #info\n",
    "\n",
    "print(\"CNTK sees device(s): \",C.all_devices())\n",
    "#Ensure we always get the same randomizer init\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the data dimensions\n",
    "input_dim_model = (1, 28, 28)    # images are 28 x 28 with 1 channel of color (gray)\n",
    "input_dim = 28*28                # used by readers to treat input data as a vector\n",
    "num_output_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is  a leaner version of 103D MNIST tutorial with some additions for logging debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is C:\\local\\cntk-2-0\\cntk\\Scripts\\CNTK-Samples-2-0\\Examples\\Image\\DataSets\\MNIST\n"
     ]
    }
   ],
   "source": [
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    \n",
    "    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n",
    "                          \n",
    "    return C.io.MinibatchSource(ctf,\n",
    "        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)\n",
    "\n",
    "data_found=False # A flag to indicate if train/test data found in local cache\n",
    "for data_dir in [os.path.join(\"C:\\local\\cntk-2-0\\cntk\\Scripts\\CNTK-Samples-2-0\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"data\", \"MNIST\")]:\n",
    "    \n",
    "    train_file=os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "    test_file=os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "    \n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found=True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "    \n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redirecting log to file mnistf.log\n"
     ]
    }
   ],
   "source": [
    "#we need a real progress printer\n",
    "progprint = C.logging.progress_print.ProgressPrinter(freq=0,first=2,log_to_file='mnistf.log')\n",
    "\n",
    "progprint.log('Initializng the Model' + repr(datetime.datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm input shape (1, 28, 28)\n",
      "confirm output shape (10,)\n"
     ]
    }
   ],
   "source": [
    "#prep our input/output containers/shapes\n",
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_output_classes)\n",
    "print('confirm input shape',x.shape)\n",
    "print('confirm output shape',y.shape)\n",
    "\n",
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)\n",
    "\n",
    "# Define a utility function to compute the moving average sum.\n",
    "# A more efficient implementation is possible with np.cumsum() function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Need to send a copy of the array\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss   = \"NA\"\n",
    "    eval_error      = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "        \n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need tensorboard installed to process the outputs from tensprint below. On windows 10 I pip installed tensorflow which includes tensorboard and then pointed the tensorboard command - all from a bash shell. Worked OK for me. Please check tensorflow and CNTK docs as this may evolve over time. The code will run regardless of tensorflow/board runtime presence - it is needed to parse and visualize the data but logging occurs independently.\n",
    "If you want this to run faster for demos just drop a '0' from the 60000 training samples - but don't expect good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=10):  #sweeps was 10\n",
    "    \n",
    "    # Instantiate the model function; x is the input (feature) variable \n",
    "    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n",
    "    tmodel = model_func(x/255)\n",
    "    \n",
    "    \n",
    "    #tensorboard logging directory - the filenames are autocreated and the tensorboard command line takes care of\n",
    "    #ingesting that log and exposing the contents via a web browser. definitely take a look at a tensorboard tutorial\n",
    "    #video\n",
    "    \n",
    "    tensprint = C.logging.TensorBoardProgressWriter(freq=10, log_dir='C:/users/jiwillia/documents/repos', model=tmodel)\n",
    "    \n",
    "    # Instantiate the loss and error function\n",
    "    loss, label_error = create_criterion_function(tmodel, y)\n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    learning_rate = 0.2\n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner],[tensprint]) #bind up trainer, learner,model,loss...\n",
    "    #note that the trainer does not have the progress printer associated with it but does have tensorboard and the \n",
    "    #progressprint writer is used independently for other logging. \n",
    "    \n",
    "    # Initialize the parameters for the trainer\n",
    "    minibatch_size = 64             #was 64\n",
    "    num_samples_per_sweep = 6000    #was 60000 - use this for demos\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "    \n",
    "    # Map the data streams to the input and labels \n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x  : train_reader.streams.features\n",
    "    } \n",
    "    # Uncomment below for more detailed logging\n",
    "    training_progress_output_freq = 500\n",
    "     \n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training data file\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map) \n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "    \n",
    "    # Test the model\n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x  : test_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 512   #original was 512\n",
    "    num_samples = 10000         #our unseen images\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0   \n",
    "\n",
    "    for i in range(num_minibatches_to_test):\n",
    "    \n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n",
    "        # with one pixel per dimension that we will encode / decode with the \n",
    "        # trained model.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add do traintest\n",
    "def do_train_test():\n",
    "        global z\n",
    "        z = create_model(x)\n",
    "        print(\"the z network model is \",repr(z))\n",
    "        print(\"model type is: \",type(z))\n",
    "        reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "        reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "        train_test(reader_train, reader_test, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intent below is to use the functional Sequantial layer call to construct the conv network with less bookeeping compared to the graph API version. The default sample uses graph and while it works just as well there are more areas for simple mistakes to surface only at runtime. Varous log statements are added to simply show ways to grab and log relevant tensor shape and paramter data. Tensorboard does create a static graph visual of the network but by grabbing the items directly you could populate other repositories. A dropout layer is added to see how they work and show up in the tensorboard graph. The best results i have seen with this model (with the dropout) has been around 99.2% accuracy for the test run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a companion to this notebook called mnistG that is almost a mirror except it uses the graph API style for creating the network. If you make an error in that create_model routine by forgetting to append the (h) then you will get an interesting runtime error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to build model using functional API approach\n",
    "def create_model(features):\n",
    "    #the defaults can be overridden at layer level\n",
    "    with C.layers.default_options(init = C.layers.glorot_uniform(), activation = C.relu):\n",
    "            r = C.layers.Sequential([\n",
    "            #features,\n",
    "            C.layers.Convolution2D(filter_shape=(5,5),num_filters=8,strides=(1,1),pad=True, name=\"First_Conv\"),\n",
    "            \n",
    "            C.layers.MaxPooling(filter_shape=(2,2), strides=(2,2), name=\"First_Max\"),\n",
    "            \n",
    "            C.layers.Convolution2D(filter_shape=(3,3),  num_filters=16, strides=(1,1), pad=True, name=\"Second_Conv\"),\n",
    "            \n",
    "            C.layers.Convolution2D(filter_shape=(5,5),num_filters=24,strides=(1,1), pad=True,name=\"Third_Conv\"),\n",
    "            \n",
    "            C.layers.MaxPooling(filter_shape=(3,3), strides=(1,1), name=\"Second_Max\"),\n",
    "            \n",
    "            C.layers.Dense(96,name='Dense96'),                              # add a layer of 96 densely connection nodes\n",
    "\n",
    "            C.layers.layers.Dropout(0.5,name='DropOutB4FinalClassifier'),   # overfit protection\n",
    "\n",
    "            C.layers.Dense(num_output_classes,activation=None,name='Classifier')\n",
    "            ]) \n",
    "\n",
    "            #r = C.layers.layers.Dropout(0.5,name='DropOutAfterDenseClassifier')(r) #jw 8/14 0.39 avg test error\n",
    "            #print(\"\\n final network\",repr(r)) #add 8/8 1:00PM - shows droput\n",
    "            cntkfunclist = C.logging.graph.depth_first_search(r(features),lambda j: (True),depth=-1)\n",
    "            progprint.log(\"CNTK Objects/Functions Dump\")\n",
    "            for afunc in cntkfunclist:\n",
    "                progprint.log(\"Name: \" + afunc.name +\" --Val: \" + repr(afunc) )\n",
    "                if type(afunc) is C.variables.Parameter:\n",
    "                    progprint.log(repr(afunc.name) + repr(afunc.value))\n",
    "                    progprint.log('---------------------------------') \n",
    "                \n",
    "            \n",
    "            print('---------------------------------------------------------------------')\n",
    "            r = r(features) #need to add the feature dimensions and shape to the model otherwise this will fail\n",
    "                            #at runtime - this is different from the graph API style where the features were passed \n",
    "                            # into model at creation\n",
    "            print(\"final model:\\n \",repr(r))            \n",
    "            #r=C.debugging.debug_model(r) - !!! do not use from non-tty enabled interfaces\n",
    "            return r                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "final model:\n",
      "  Composite(Dense): Input('Input2439', [#], [1 x 28 x 28]) -> Output('Classifier', [#], [10])\n",
      "the z network model is  Composite(Dense): Input('Input2439', [#], [1 x 28 x 28]) -> Output('Classifier', [#], [10])\n",
      "model type is:  <class 'cntk.ops.functions.Function'>\n",
      "Minibatch: 0, Loss: 2.3748, Error: 92.19%\n",
      "Minibatch: 500, Loss: 0.2557, Error: 12.50%\n",
      "Training took 107.9 sec\n",
      "Average test error: 1.81%\n"
     ]
    }
   ],
   "source": [
    "do_train_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
